Namespace,Pod Name,Status,Restart Count,Failure Reasons,Logs,Failure_Label
default,bad-image-pod,Pending,3,ContainersNotReady | ErrImagePull,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,3,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,metrics-server-f456fcfb-db6n6,Running,1,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,4,,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,4,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,4,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,11,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod-synthetic-705,Pending,2,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-921,Pending,2,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Error 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-826,Pending,1,ContainersNotReady | ErrImagePull,"Error waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-367,Pending,2,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Error Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-550,Pending,6,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Warning \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-856,Pending,3,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Error 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-697,Pending,2,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Error to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-484,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Warning is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-109,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Error 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-165,Pending,2,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-257,Pending,2,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Error 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-520,Pending,2,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-567,Pending,4,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-920,Pending,4,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-394,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Error 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-809,Pending,4,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Error 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-711,Pending,4,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Error body: pull GMT', waiting WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-320,Pending,0,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-273,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Warning to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-688,Pending,5,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Warning private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-834,Pending,2,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Error 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-372,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Warning \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-483,Pending,4,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-908,Pending,4,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-178,Pending,4,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Warning response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-624,Pending,3,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Error Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-509,Pending,1,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error and start: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-481,Pending,3,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Error HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-705,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Error and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-123,Pending,4,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Error \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-432,Pending,4,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-387,Pending,6,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Error 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-685,Pending,5,ContainersNotReady | ImagePullBackOff,"Error 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-593,Pending,5,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Error logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-709,Pending,2,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Error 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-620,Pending,2,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Error response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-763,Pending,6,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-423,Pending,1,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-696,Pending,2,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-547,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Warning trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-599,Pending,3,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Bad Request 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-915,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-104,Pending,6,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Error 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-858,Pending,2,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-361,Pending,3,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Warning Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-898,Pending,3,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-829,Pending,0,ContainersNotReady | ImagePullBackOff,"to (400) Request Error response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-505,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-640,Pending,2,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-348,Pending,5,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Error GMT', '225'}) to Bad Request logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-284,Pending,0,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Error HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Warning (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-711,Pending,4,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-796,Pending,4,ContainersNotReady | ImagePullBackOff,"pod Error image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-577,Pending,3,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-428,Pending,5,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Error Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-757,Pending,5,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-792,Pending,1,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Warning in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-936,Pending,4,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Error Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,4,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-599,Pending,3,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-316,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Error image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-697,Pending,5,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Error 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-590,Pending,4,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-785,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Error Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-107,Pending,4,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Error to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-242,Pending,5,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Bad Request pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Error response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-574,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Warning image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-974,Pending,1,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Error trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-268,Pending,0,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Error 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-930,Pending,1,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Warning (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-651,Pending,2,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-147,Pending,5,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Error 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-406,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Error 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-824,Pending,1,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Warning fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-379,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-678,Pending,1,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Error Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-935,Pending,0,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-120,Pending,5,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Error to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-716,Pending,2,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-856,Pending,1,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Warning trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-488,Pending,5,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Warning 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-898,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Error headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-524,Pending,2,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Warning pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-683,Pending,0,ContainersNotReady | ImagePullBackOff,"body: Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-555,Pending,3,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Error 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-118,Pending,6,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Error 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-841,Pending,2,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Error 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-629,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-742,Pending,4,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Error 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-842,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Error response body: HTTP start: Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-750,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Error Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-444,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Error 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-170,Pending,5,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Error response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-285,Pending,0,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Error response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-156,Pending,4,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-875,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-226,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-789,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Error 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,1,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Error 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-621,Pending,1,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Error 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-951,Pending,6,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Error 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-801,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTP Request Error GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-515,Pending,2,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Error trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-902,Pending,5,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Warning 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.",1
default,bad-image-pod,Pending,0,ContainersNotReady | ErrImagePull,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,metrics-server-f456fcfb-db6n6,Running,1,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,3,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,6,,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod-synthetic-705,Pending,1,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-921,Pending,6,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Warning 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-826,Pending,0,ContainersNotReady | ErrImagePull,"Error waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-367,Pending,0,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Error Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-550,Pending,4,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Error \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-856,Pending,1,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Warning 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-697,Pending,3,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Error to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-484,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Warning is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-109,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Error 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-165,Pending,3,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-257,Pending,1,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Warning 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-520,Pending,2,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-567,Pending,2,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-920,Pending,1,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-394,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Error 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-809,Pending,4,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Error 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-711,Pending,4,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Error body: pull GMT', waiting WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-320,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-273,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Warning to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-688,Pending,3,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Error private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-834,Pending,1,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Error 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-372,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Error \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-483,Pending,4,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-908,Pending,4,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-178,Pending,2,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Warning response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-624,Pending,1,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Error Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,0,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Warning and start: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-481,Pending,2,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Error HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-705,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Error and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-123,Pending,1,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Error \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-432,Pending,2,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-387,Pending,5,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Error 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-685,Pending,4,ContainersNotReady | ImagePullBackOff,"Error 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-593,Pending,1,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Warning logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-709,Pending,2,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Error 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-620,Pending,3,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Error response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-763,Pending,5,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-423,Pending,4,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-696,Pending,0,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-547,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Error trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-599,Pending,4,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Unauthorized Access 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-915,Pending,0,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-104,Pending,5,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Warning 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-858,Pending,3,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-361,Pending,2,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Error Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-898,Pending,6,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-829,Pending,0,ContainersNotReady | ImagePullBackOff,"to (400) Request Error response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-505,Pending,0,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-640,Pending,6,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-348,Pending,3,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Error GMT', '225'}) to Bad Request logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-284,Pending,0,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Error HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,0,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Error (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-711,Pending,5,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-796,Pending,3,ContainersNotReady | ImagePullBackOff,"pod Error image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-577,Pending,4,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-428,Pending,5,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Error Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-757,Pending,4,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-792,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Error in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-936,Pending,4,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Error Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,5,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-599,Pending,2,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-316,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Warning image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-697,Pending,2,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Error 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-590,Pending,0,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-785,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Error Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-107,Pending,1,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Error to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-242,Pending,3,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Bad Request pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Error response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-574,Pending,3,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Error image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-974,Pending,5,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Error trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-268,Pending,3,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Warning 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-930,Pending,1,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Error (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-651,Pending,6,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-147,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Warning 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-406,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Error 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-824,Pending,3,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Error fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-379,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-678,Pending,0,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Error Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-935,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-120,Pending,4,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Error to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-716,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-856,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-488,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Error 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-898,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Error headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-524,Pending,2,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Warning pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-683,Pending,4,ContainersNotReady | ImagePullBackOff,"body: Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-555,Pending,2,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Error 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-118,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Error 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-841,Pending,2,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Error 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-629,Pending,1,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-742,Pending,1,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Error 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-842,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Warning response body: HTTP start: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-750,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Error Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-444,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Warning 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-170,Pending,4,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Error response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-285,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Error response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-156,Pending,4,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-875,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-226,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-789,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Error 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,2,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Error 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-621,Pending,1,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Warning 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-951,Pending,6,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Error 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-801,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTP Request Error GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-515,Pending,1,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Error trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-902,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Error 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod,Pending,2,ContainersNotReady | ErrImagePull,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,4,ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,metrics-server-f456fcfb-db6n6,Running,1,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,4,,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,5,ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,7,,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,11,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod-synthetic-705,Pending,4,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-921,Pending,4,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Error 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-826,Pending,1,ContainersNotReady | ErrImagePull,"Error waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-367,Pending,1,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Error Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-550,Pending,6,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Error \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-856,Pending,3,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Warning 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-697,Pending,1,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Error to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-484,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Error is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-109,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Warning 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-165,Pending,3,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-257,Pending,1,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Error 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-520,Pending,2,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-567,Pending,4,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-920,Pending,4,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-394,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Warning 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-809,Pending,1,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Error 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-711,Pending,4,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Error body: pull GMT', waiting WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-320,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-273,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Error to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-688,Pending,4,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Error private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-834,Pending,4,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Warning 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-372,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Error \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-483,Pending,4,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-908,Pending,3,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-178,Pending,2,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Error response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-624,Pending,2,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Error Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,0,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error and start: Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-481,Pending,4,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Error HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-705,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Error and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-123,Pending,4,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Error \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-432,Pending,5,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-387,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Error 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-685,Pending,4,ContainersNotReady | ImagePullBackOff,"Error 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-593,Pending,4,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Warning logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-709,Pending,5,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Error 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-620,Pending,2,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Error response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-763,Pending,2,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-423,Pending,3,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-696,Pending,3,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-547,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Error trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-599,Pending,2,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Bad Request 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-915,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-104,Pending,3,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Warning 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-858,Pending,1,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-361,Pending,1,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Warning Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-898,Pending,4,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-829,Pending,4,ContainersNotReady | ImagePullBackOff,"to (400) Request Error response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-505,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-640,Pending,4,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-348,Pending,5,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Error GMT', '225'}) to Bad Request logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-284,Pending,1,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Error HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-590,Pending,0,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Error (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-711,Pending,1,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-796,Pending,5,ContainersNotReady | ImagePullBackOff,"pod Error image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-577,Pending,2,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-428,Pending,6,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Error Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-757,Pending,3,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-792,Pending,0,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Error in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-936,Pending,3,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Error Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,2,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-599,Pending,1,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-316,Pending,6,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Error image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-697,Pending,6,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Error 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-590,Pending,0,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-785,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Warning Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-107,Pending,4,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Warning to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-242,Pending,5,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Unauthorized Access pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Error response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-574,Pending,5,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Error image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-974,Pending,2,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Error trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-268,Pending,0,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Error 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-930,Pending,4,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Error (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-651,Pending,2,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-147,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Warning 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-406,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Error 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-824,Pending,2,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Error fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-379,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-678,Pending,3,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Error Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-935,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-120,Pending,5,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Error to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-716,Pending,2,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-856,Pending,1,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-488,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Error 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-898,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Error headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-524,Pending,3,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Warning pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-683,Pending,0,ContainersNotReady | ImagePullBackOff,"body: Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-555,Pending,5,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Error 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-118,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Error 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-841,Pending,5,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Error 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-629,Pending,5,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-742,Pending,5,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Error 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-842,Pending,5,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Error response body: HTTP start: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-750,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Warning Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-444,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Error 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-170,Pending,2,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Warning response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-285,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Warning response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-156,Pending,2,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-875,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-226,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-789,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Error 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,5,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Error 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-621,Pending,1,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Error 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-951,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Error 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-801,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTP Request Warning GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-515,Pending,3,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Error trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-902,Pending,5,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Error 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.",1
default,bad-image-pod,Pending,1,ContainersNotReady | ErrImagePull,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,3,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,metrics-server-f456fcfb-db6n6,Running,1,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,4,,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,11,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod-synthetic-705,Pending,2,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-921,Pending,3,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Error 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-826,Pending,2,ContainersNotReady | ErrImagePull,"Error waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-367,Pending,0,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Error Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-550,Pending,2,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Error \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-856,Pending,1,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Error 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-697,Pending,5,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Error to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-484,Pending,6,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Error is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-109,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Error 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-165,Pending,3,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-257,Pending,0,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Error 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-520,Pending,0,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-567,Pending,4,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-920,Pending,3,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-394,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Warning 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-809,Pending,4,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Error 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-711,Pending,3,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Error body: pull GMT', waiting WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-320,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-273,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Error to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-688,Pending,2,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Error private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-834,Pending,3,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Error 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-372,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Error \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-483,Pending,0,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-908,Pending,3,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-178,Pending,5,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Error response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-624,Pending,2,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Warning Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,1,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error and start: Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-481,Pending,4,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Error HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-705,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Error and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-123,Pending,2,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Error \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-432,Pending,5,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-387,Pending,6,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Error 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-685,Pending,5,ContainersNotReady | ImagePullBackOff,"Error 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-593,Pending,2,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Error logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-709,Pending,3,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Warning 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-620,Pending,5,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Error response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-763,Pending,6,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-423,Pending,4,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-696,Pending,3,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-547,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Error trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-599,Pending,2,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Unauthorized Access 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-915,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-104,Pending,4,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Error 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-858,Pending,4,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-361,Pending,3,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Error Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-898,Pending,2,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-829,Pending,4,ContainersNotReady | ImagePullBackOff,"to (400) Request Error response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-505,Pending,4,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-640,Pending,6,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-348,Pending,6,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Error GMT', '225'}) to Bad Request logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-284,Pending,1,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Error HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-590,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Error (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-711,Pending,5,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-796,Pending,4,ContainersNotReady | ImagePullBackOff,"pod Error image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-577,Pending,0,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-428,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Error Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-757,Pending,2,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-792,Pending,1,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Error in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-936,Pending,3,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Warning Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,2,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-599,Pending,3,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-316,Pending,2,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Warning image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-697,Pending,2,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Error 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,2,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-785,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Error Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-107,Pending,1,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Error to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-242,Pending,2,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Unauthorized Access pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Error response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-574,Pending,5,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Error image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-974,Pending,2,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Error trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-268,Pending,1,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Error 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-930,Pending,5,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Error (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-651,Pending,5,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-147,Pending,5,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Error 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-406,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Warning 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-824,Pending,2,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Error fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-379,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-678,Pending,4,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Warning Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-935,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-120,Pending,4,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Error to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-716,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-856,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-488,Pending,2,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Error 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-898,Pending,3,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Error headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-524,Pending,3,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Error pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-683,Pending,0,ContainersNotReady | ImagePullBackOff,"body: Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-555,Pending,2,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Error 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-118,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Error 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-841,Pending,2,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Error 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-629,Pending,3,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-742,Pending,4,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Error 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-842,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Error response body: HTTP start: Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-750,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Warning Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-444,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Error 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-170,Pending,4,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Error response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-285,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Error response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-156,Pending,3,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-875,Pending,5,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-226,Pending,5,ContainersNotReady | ImagePullBackOff,"Error fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-789,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Error 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,1,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Error 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-621,Pending,1,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Error 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-951,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Error 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-801,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP Request Error GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-515,Pending,3,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Error trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-902,Pending,6,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Error 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.",1
default,bad-image-pod,Pending,1,ContainersNotReady | ErrImagePull,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,5,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,metrics-server-f456fcfb-db6n6,Running,2,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,3,,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,8,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,6,,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod-synthetic-705,Pending,4,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-921,Pending,2,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Error 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-826,Pending,0,ContainersNotReady | ErrImagePull,"Warning waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-367,Pending,3,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Warning Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-550,Pending,3,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Warning \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-856,Pending,3,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Error 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-697,Pending,4,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Warning to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-484,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Warning is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-109,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Error 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-165,Pending,1,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-257,Pending,0,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Error 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-520,Pending,1,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-567,Pending,3,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-920,Pending,5,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-394,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Error 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-809,Pending,2,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Error 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-711,Pending,5,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Warning body: pull GMT', waiting WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-320,Pending,0,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-273,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Error to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-688,Pending,2,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Warning private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-834,Pending,4,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Warning 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-372,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Error \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-483,Pending,1,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-908,Pending,4,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-178,Pending,3,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Error response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-624,Pending,0,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Error Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-509,Pending,2,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error and start: Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-481,Pending,5,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Error HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-705,Pending,0,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Warning and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-123,Pending,1,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Error \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-432,Pending,3,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-387,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Error 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-685,Pending,4,ContainersNotReady | ImagePullBackOff,"Error 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-593,Pending,4,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Error logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-709,Pending,5,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Error 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-620,Pending,1,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Error response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-763,Pending,3,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-423,Pending,4,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-696,Pending,2,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-547,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Error trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-599,Pending,3,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Bad Request 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-915,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-104,Pending,5,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Error 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-858,Pending,2,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-361,Pending,2,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Error Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-898,Pending,5,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-829,Pending,4,ContainersNotReady | ImagePullBackOff,"to (400) Request Error response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-505,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-640,Pending,2,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-348,Pending,3,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Error GMT', '225'}) to Unauthorized Access logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-284,Pending,0,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Error HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-590,Pending,1,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Error (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-711,Pending,1,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Error ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-796,Pending,1,ContainersNotReady | ImagePullBackOff,"pod Error image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-577,Pending,0,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-428,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Error Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-757,Pending,1,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-792,Pending,1,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Error in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-936,Pending,3,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Error Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,4,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-599,Pending,2,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-316,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Error image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-697,Pending,4,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Error 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,1,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-785,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Error Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-107,Pending,1,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Error to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-242,Pending,4,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Bad Request pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Error response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-574,Pending,3,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Error image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-974,Pending,3,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Warning trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-268,Pending,1,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Error 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-930,Pending,4,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Error (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-651,Pending,5,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-147,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Warning 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-406,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Error 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-824,Pending,5,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Error fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-379,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-678,Pending,2,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Error Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-935,Pending,0,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-120,Pending,5,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Error to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-716,Pending,2,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-856,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-488,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Error 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-898,Pending,1,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Warning headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-524,Pending,3,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Error pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-683,Pending,2,ContainersNotReady | ImagePullBackOff,"body: Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-555,Pending,1,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Error 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-118,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Warning 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-841,Pending,4,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Error 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-629,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-742,Pending,4,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Error 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-842,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Error response body: HTTP start: Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-750,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Error Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-444,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Error 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-170,Pending,4,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Error response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-285,Pending,0,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Error response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-156,Pending,3,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-875,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Warning failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-226,Pending,5,ContainersNotReady | ImagePullBackOff,"Error fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-789,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Error 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,4,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Error 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-621,Pending,1,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Error 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-951,Pending,5,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Warning 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-801,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP Request Error GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-515,Pending,4,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Error trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-902,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Error 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod,Pending,0,ContainersNotReady | ErrImagePull,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,2,ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,metrics-server-f456fcfb-db6n6,Running,2,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,4,,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,4,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,6,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod-synthetic-705,Pending,3,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-921,Pending,4,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Error 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-826,Pending,2,ContainersNotReady | ErrImagePull,"Error waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-367,Pending,2,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Error Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-550,Pending,5,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Error \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-856,Pending,0,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Error 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-697,Pending,2,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Warning to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-484,Pending,5,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Error is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-109,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Error 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-165,Pending,3,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-257,Pending,3,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Error 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-520,Pending,4,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-567,Pending,1,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-920,Pending,3,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-394,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Error 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-809,Pending,2,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Error 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-711,Pending,3,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Error body: pull GMT', waiting WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-320,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-273,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Error to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-688,Pending,2,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Warning private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-834,Pending,1,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Error 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-372,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Error \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-483,Pending,0,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-908,Pending,6,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-178,Pending,3,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Error response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-624,Pending,3,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Error Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-509,Pending,2,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error and start: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-481,Pending,4,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Error HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-705,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Warning and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-123,Pending,3,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Error \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-432,Pending,3,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-387,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Warning 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-685,Pending,6,ContainersNotReady | ImagePullBackOff,"Error 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-593,Pending,3,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Error logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-709,Pending,4,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Error 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-620,Pending,4,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Warning response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-763,Pending,3,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-423,Pending,2,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-696,Pending,4,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-547,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Error trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-599,Pending,2,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Bad Request 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-915,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-104,Pending,6,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Error 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-858,Pending,2,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-361,Pending,1,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Error Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-898,Pending,6,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-829,Pending,2,ContainersNotReady | ImagePullBackOff,"to (400) Request Error response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-505,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-640,Pending,5,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-348,Pending,2,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Error GMT', '225'}) to Bad Request logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-284,Pending,0,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Warning HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,1,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Error (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-711,Pending,2,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-796,Pending,4,ContainersNotReady | ImagePullBackOff,"pod Error image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-577,Pending,4,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-428,Pending,6,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Error Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-757,Pending,2,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-792,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Error in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-936,Pending,3,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Warning Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,6,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-599,Pending,4,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-316,Pending,2,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Error image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-697,Pending,6,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Error 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,4,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-785,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Error Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-107,Pending,3,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Error to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-242,Pending,5,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Bad Request pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Error response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-574,Pending,5,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Error image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-974,Pending,4,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Error trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-268,Pending,0,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Error 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-930,Pending,1,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Warning (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-651,Pending,6,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-147,Pending,5,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Error 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-406,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Error 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-824,Pending,3,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Error fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-379,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-678,Pending,1,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Error Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-935,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-120,Pending,3,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Error to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-716,Pending,6,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-856,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-488,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Error 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-898,Pending,1,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Warning headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-524,Pending,5,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Error pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-683,Pending,4,ContainersNotReady | ImagePullBackOff,"body: Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-555,Pending,1,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Warning 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-118,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Warning 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-841,Pending,1,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Error 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-629,Pending,1,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-742,Pending,1,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Error 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-842,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Warning response body: HTTP start: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-750,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Error Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-444,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Warning 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-170,Pending,3,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Error response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-285,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Error response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-156,Pending,2,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-875,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-226,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-789,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Warning 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,1,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Error 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-621,Pending,3,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Warning 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-951,Pending,4,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Error 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-801,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP Request Error GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-515,Pending,1,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Warning trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-902,Pending,5,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Warning 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.",1
default,bad-image-pod,Pending,2,ContainersNotReady | ErrImagePull,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,metrics-server-f456fcfb-db6n6,Running,2,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,5,,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,9,,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,11,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod-synthetic-705,Pending,3,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-921,Pending,3,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Error 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-826,Pending,3,ContainersNotReady | ErrImagePull,"Error waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-367,Pending,0,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Error Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-550,Pending,3,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Error \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-856,Pending,1,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Error 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-697,Pending,3,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Error to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-484,Pending,4,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Error is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-109,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Error 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-165,Pending,4,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-257,Pending,4,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Error 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-520,Pending,1,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-567,Pending,1,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-920,Pending,2,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-394,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Error 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-809,Pending,4,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Error 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-711,Pending,1,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Error body: pull GMT', waiting WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-320,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-273,Pending,0,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Error to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-688,Pending,2,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Error private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-834,Pending,2,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Error 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-372,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Error \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-483,Pending,3,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-908,Pending,3,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-178,Pending,5,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Error response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-624,Pending,1,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Error Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,3,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error and start: Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-481,Pending,4,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Error HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-705,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Error and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-123,Pending,5,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Error \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-432,Pending,3,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-387,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Error 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-685,Pending,6,ContainersNotReady | ImagePullBackOff,"Error 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-593,Pending,3,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Error logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-709,Pending,6,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Warning 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-620,Pending,1,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Error response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-763,Pending,3,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-423,Pending,4,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-696,Pending,1,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-547,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Error trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-599,Pending,2,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Bad Request 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-915,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-104,Pending,5,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Error 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-858,Pending,4,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-361,Pending,3,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Error Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-898,Pending,5,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-829,Pending,4,ContainersNotReady | ImagePullBackOff,"to (400) Request Error response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-505,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-640,Pending,5,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-348,Pending,5,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Error GMT', '225'}) to Bad Request logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-284,Pending,4,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Error HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Warning (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-711,Pending,2,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-796,Pending,4,ContainersNotReady | ImagePullBackOff,"pod Warning image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-577,Pending,1,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-428,Pending,3,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Warning Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-757,Pending,2,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-792,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Error in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-936,Pending,2,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Error Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,3,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-599,Pending,5,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-316,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Error image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-697,Pending,5,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Error 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,4,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-785,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Error Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-107,Pending,4,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Error to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-242,Pending,3,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Bad Request pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Error response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-574,Pending,1,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Error image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-974,Pending,5,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Error trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-268,Pending,4,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Error 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-930,Pending,4,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Error (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-651,Pending,4,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-147,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Error 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-406,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Error 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-824,Pending,3,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Error fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-379,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-678,Pending,0,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Error Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-935,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-120,Pending,5,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Error to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-716,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-856,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-488,Pending,5,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Error 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-898,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Error headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-524,Pending,5,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Error pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-683,Pending,0,ContainersNotReady | ImagePullBackOff,"body: Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-555,Pending,3,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Error 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-118,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Error 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-841,Pending,2,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Warning 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-629,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-742,Pending,4,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Error 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-842,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Error response body: HTTP start: Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-750,Pending,1,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Error Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-444,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Error 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-170,Pending,5,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Error response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-285,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Error response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-156,Pending,4,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-875,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-226,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-789,Pending,1,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Error 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-509,Pending,4,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Error 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-621,Pending,2,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Error 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-951,Pending,5,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Error 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-801,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTP Request Error GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-515,Pending,1,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Error trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-902,Pending,5,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Warning 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.",1
default,bad-image-pod,Pending,2,ContainersNotReady | ErrImagePull,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,3,ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,metrics-server-f456fcfb-db6n6,Running,1,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,3,,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,8,ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,9,,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,11,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod-synthetic-705,Pending,1,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-921,Pending,5,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Warning 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-826,Pending,1,ContainersNotReady | ErrImagePull,"Error waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-367,Pending,0,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Error Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-550,Pending,4,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Error \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-856,Pending,4,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Error 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-697,Pending,1,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Error to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-484,Pending,6,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Warning is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-109,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Error 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-165,Pending,5,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-257,Pending,1,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Error 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-520,Pending,3,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-567,Pending,0,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-920,Pending,5,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-394,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Error 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-809,Pending,5,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Warning 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-711,Pending,3,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Error body: pull GMT', waiting WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-320,Pending,1,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-273,Pending,4,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Warning to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-688,Pending,6,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Error private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-834,Pending,0,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Warning 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-372,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Error \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-483,Pending,2,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-908,Pending,3,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-178,Pending,6,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Error response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-624,Pending,0,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Error Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,0,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error and start: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-481,Pending,1,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Warning HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-705,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Error and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-123,Pending,5,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Error \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-432,Pending,4,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-387,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Error 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-685,Pending,3,ContainersNotReady | ImagePullBackOff,"Error 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-593,Pending,2,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Error logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-709,Pending,4,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Warning 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-620,Pending,5,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Error response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-763,Pending,3,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-423,Pending,1,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-696,Pending,2,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-547,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Error trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-599,Pending,2,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Unauthorized Access 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-915,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-104,Pending,2,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Warning 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-858,Pending,5,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-361,Pending,4,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Error Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-898,Pending,3,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-829,Pending,3,ContainersNotReady | ImagePullBackOff,"to (400) Request Warning response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-505,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-640,Pending,6,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-348,Pending,6,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Warning GMT', '225'}) to Bad Request logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-284,Pending,3,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Error HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-590,Pending,3,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Warning (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-711,Pending,1,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-796,Pending,4,ContainersNotReady | ImagePullBackOff,"pod Error image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-577,Pending,0,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-428,Pending,6,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Error Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-757,Pending,4,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-792,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Error in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-936,Pending,2,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Error Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,5,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-599,Pending,1,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-316,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Error image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-697,Pending,2,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Warning 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,1,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-785,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Error Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-107,Pending,5,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Warning to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-242,Pending,1,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Bad Request pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Error response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-574,Pending,5,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Error image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-974,Pending,4,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Error trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-268,Pending,1,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Error 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-930,Pending,5,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Error (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-651,Pending,2,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-147,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Error 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-406,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Warning 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-824,Pending,5,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Error fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-379,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-678,Pending,3,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Warning Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-935,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-120,Pending,5,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Error to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-716,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-856,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-488,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Error 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-898,Pending,3,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Error headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-524,Pending,1,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Error pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-683,Pending,3,ContainersNotReady | ImagePullBackOff,"body: Warning {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-555,Pending,5,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Error 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-118,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Error 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-841,Pending,2,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Error 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-629,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-742,Pending,4,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Error 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-842,Pending,5,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Error response body: HTTP start: Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-750,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Error Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-444,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Error 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-170,Pending,4,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Error response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-285,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Error response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-156,Pending,5,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-875,Pending,6,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-226,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-789,Pending,1,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Error 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,4,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Error 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-621,Pending,4,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Warning 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-951,Pending,4,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Error 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-801,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP Request Error GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-515,Pending,4,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Error trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-902,Pending,2,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Error 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod,Pending,1,ContainersNotReady | ErrImagePull,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,4,ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,metrics-server-f456fcfb-db6n6,Running,3,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,3,,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,11,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod-synthetic-705,Pending,4,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-921,Pending,2,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Warning 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-826,Pending,0,ContainersNotReady | ErrImagePull,"Error waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-367,Pending,4,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Error Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-550,Pending,4,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Warning \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-856,Pending,0,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Error 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-697,Pending,5,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Error to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-484,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Error is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-109,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Error 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-165,Pending,1,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-257,Pending,1,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Error 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-520,Pending,3,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-567,Pending,3,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-920,Pending,5,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-394,Pending,6,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Error 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-809,Pending,5,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Error 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-711,Pending,5,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Error body: pull GMT', waiting WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-320,Pending,0,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-273,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Error to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-688,Pending,3,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Error private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-834,Pending,4,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Error 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-372,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Error \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-483,Pending,3,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-908,Pending,2,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-178,Pending,3,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Error response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-624,Pending,1,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Error Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-509,Pending,1,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error and start: Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-481,Pending,1,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Warning HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-705,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Error and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-123,Pending,5,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Error \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-432,Pending,2,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-387,Pending,6,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Error 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-685,Pending,2,ContainersNotReady | ImagePullBackOff,"Error 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-593,Pending,4,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Error logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-709,Pending,4,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Error 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-620,Pending,5,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Warning response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-763,Pending,6,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-423,Pending,3,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-696,Pending,3,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-547,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Error trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-599,Pending,3,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Bad Request 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-915,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-104,Pending,2,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Error 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-858,Pending,3,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-361,Pending,1,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Error Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-898,Pending,6,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-829,Pending,2,ContainersNotReady | ImagePullBackOff,"to (400) Request Error response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-505,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-640,Pending,4,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-348,Pending,2,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Warning GMT', '225'}) to Bad Request logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-284,Pending,1,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Error HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-590,Pending,3,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Error (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-711,Pending,2,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Warning ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-796,Pending,4,ContainersNotReady | ImagePullBackOff,"pod Error image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-577,Pending,2,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-428,Pending,6,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Error Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-757,Pending,1,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-792,Pending,4,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Error in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-936,Pending,5,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Warning Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,4,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-599,Pending,3,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-316,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Error image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-697,Pending,5,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Warning 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-590,Pending,0,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-785,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Error Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-107,Pending,5,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Warning to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-242,Pending,3,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Bad Request pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Warning response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-574,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Error image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-974,Pending,3,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Error trying Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-268,Pending,2,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Warning 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-930,Pending,1,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Error (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-651,Pending,5,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-147,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Error 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-406,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Warning 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-824,Pending,1,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Error fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-379,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-678,Pending,0,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Error Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-935,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-120,Pending,1,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Warning to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-716,Pending,6,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-856,Pending,0,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Warning trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-488,Pending,6,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Warning 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-898,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Error headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-524,Pending,5,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Error pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-683,Pending,3,ContainersNotReady | ImagePullBackOff,"body: Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-555,Pending,5,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Error 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-118,Pending,6,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Warning 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-841,Pending,1,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Error 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-629,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-742,Pending,5,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Error 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-842,Pending,2,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Error response body: HTTP start: Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-750,Pending,4,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Error Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-444,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Error 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-170,Pending,2,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Error response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-285,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Error response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-156,Pending,2,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-875,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-226,Pending,4,ContainersNotReady | ImagePullBackOff,"Warning fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-789,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Error 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-509,Pending,1,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Warning 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-621,Pending,2,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Error 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-951,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Error 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-801,Pending,5,ContainersNotReady | ImagePullBackOff,"HTTP Request Error GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-515,Pending,2,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Warning trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-902,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Error 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.",1
default,bad-image-pod,Pending,1,ContainersNotReady | ErrImagePull,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:34:17 GMT', 'Content-Length': '214'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: image can't be pulled"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,3,ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,3,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,ContainersNotReady,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,metrics-server-f456fcfb-db6n6,Running,3,,"I0317 16:04:01.631285       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:04:01.737477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:04:01.737493       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:04:01.737514       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:04:01.737520       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0317 16:04:01.737522       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:04:01.737537       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:35:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,3,,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd53f52db-183b-4e96-973f-42f3440974dd', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:36:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,5,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,0,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:37:17 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,4,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:38:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,4,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:39:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Disk IO error encountered.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:40:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Disk IO error encountered.",1
default,crash-pod,Running,5,ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Pod failed due to high memory consumption.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,5,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:41:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:42:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,6,CrashLoopBackOff | ContainersNotReady,"Crash Test

Additional debug info: Timeout detected.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:43:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,1,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Additional debug info: Timeout detected.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '571231c7-4677-4df0-91cb-e095605f7d9d', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:44:18 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:45:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Disk IO error encountered.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Warning fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:46:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Disk IO error encountered.",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,0,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:47:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test

Disk IO error encountered.",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Pod failed due to high memory consumption.",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,1,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Pod failed due to high memory consumption.",0
kube-system,kube-proxy-2nh4w,Running,1,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Unauthorized Access
HTTP response headers: HTTPHeaderDict({'Audit-Id': '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:48:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-5869d7778c-pvpvn,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Disk IO error encountered.",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,4,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:49:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}

",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-pod,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Additional debug info: Timeout detected.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Disk IO error encountered.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Disk IO error encountered.",0
kube-system,storage-provisioner,Running,4,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,3,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:50:19 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,7,CrashLoopBackOff | ContainersNotReady,"Failure Test
",0
default,failing-readiness-pod,Running,3,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Disk IO error encountered.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,3,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,4,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,2,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,3,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,0,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:51:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,9,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,2,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,4,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,4,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr
Additional debug info: Timeout detected.",0
kube-system,kube-proxy-2nh4w,Running,2,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,1,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,1,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Additional debug info: Timeout detected.",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '2d1a1234-6455-4e92-a9c0-4fad33012904', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:52:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Additional debug info: Timeout detected.",1
default,crash-pod,Running,11,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,1,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,1,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Disk IO error encountered.",0
kube-system,kube-apiserver-minikube,Running,3,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Pod failed due to high memory consumption.",0
kube-system,kube-scheduler-minikube,Running,4,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Warning looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform
Pod failed due to high memory consumption.",0
kube-system,storage-provisioner,Running,3,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Additional debug info: Timeout detected.",0
default,bad-image-pod,Pending,1,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': '1384d15b-3c42-4e9a-b239-184678b05a17', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:53:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,10,CrashLoopBackOff | ContainersNotReady,"Crash Test

Pod failed due to high memory consumption.",0
default,failing-readiness-pod,Running,0,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
default,nginx-5869d7778c-pvpvn,Running,1,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,2,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit",0
kube-system,coredns-668d6bf9bc-bml8n,Running,0,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade",0
kube-system,etcd-minikube,Running,2,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k",0
kube-system,kube-apiserver-minikube,Running,2,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri",0
kube-system,kube-controller-manager-minikube,Running,0,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,3,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Disk IO error encountered.",0
kube-system,kube-scheduler-minikube,Running,2,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1
Pod failed due to high memory consumption.",0
kube-system,metrics-server-57c6857795-hgscc,Running,0,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,2,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr",0
default,bad-image-pod,Pending,2,ContainersNotReady | ImagePullBackOff,"Error fetching logs: (400)
Reason: Bad Request
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'Date': 'Mon, 17 Mar 2025 16:54:20 GMT', 'Content-Length': '225'})
HTTP response body: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" in pod \""bad-image-pod\"" is waiting to start: trying and failing to pull image"",""reason"":""BadRequest"",""code"":400}


Pod failed due to high memory consumption.",1
default,crash-pod,Running,8,CrashLoopBackOff | ContainersNotReady,"Crash Test
",0
default,failing-readiness-pod,Running,1,ContainersNotReady,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:32:28 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:32:28 [notice] 1#1: nginx/1.27.4
2025/03/17 16:32:28 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:32:28 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Additional debug info: Timeout detected.",0
default,nginx-5869d7778c-pvpvn,Running,3,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:29:49 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:29:49 [notice] 1#1: nginx/1.27.4
2025/03/17 16:29:49 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:29:49 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
default,nginx-pod,Running,0,,"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/03/17 16:30:06 [notice] 1#1: using the ""epoll"" event method
2025/03/17 16:30:06 [notice] 1#1: nginx/1.27.4
2025/03/17 16:30:06 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2025/03/17 16:30:06 [notice] 1#1: OS: Linux 6.12.5-linuxkit
Pod failed due to high memory consumption.",0
kube-system,coredns-668d6bf9bc-bml8n,Running,2,,"[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/ready: Still waiting on: ""kubernetes""
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = e7e8a6c4578bf29b9f453cb54ade
Pod failed due to high memory consumption.",0
kube-system,etcd-minikube,Running,3,,"{""level"":""warn"",""ts"":""2025-03-17T16:03:27.907458Z"",""caller"":""embed/config.go:689"",""msg"":""Running http and grpc server on single port. This is not recommended for production.""}
{""level"":""info"",""ts"":""2025-03-17T16:03:27.907802Z"",""caller"":""etcdmain/etcd.go:73"",""msg"":""Running: "",""args"":[""etcd"",""--advertise-client-urls=https://192.168.49.2:2379"",""--cert-file=/var/lib/minikube/certs/etcd/server.crt"",""--client-cert-auth=true"",""--data-dir=/var/lib/minikube/etcd"",""--experimental-initial-corrupt-check=true"",""--experimental-watch-progress-notify-interval=5s"",""--initial-advertise-peer-urls=https://192.168.49.2:2380"",""--initial-cluster=minikube=https://192.168.49.2:2380"",""--key-file=/var/lib/minikube/certs/etcd/server.key"",""--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379"",""--listen-metrics-urls=http://127.0.0.1:2381"",""--listen-peer-urls=https://192.168.49.2:2380"",""--name=minikube"",""--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt"",""--peer-client-cert-auth=true"",""--peer-k
Additional debug info: Timeout detected.",0
kube-system,kube-apiserver-minikube,Running,0,,"W0317 16:03:28.055482       1 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
I0317 16:03:28.056235       1 options.go:238] external host was not specified, using 192.168.49.2
I0317 16:03:28.057680       1 server.go:143] Version: v1.32.0
I0317 16:03:28.057704       1 server.go:145] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.243169       1 shared_informer.go:313] Waiting for caches to sync for node_authorizer
I0317 16:03:28.247667       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0317 16:03:28.249716       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestri
Additional debug info: Timeout detected.",0
kube-system,kube-controller-manager-minikube,Running,4,,"I0317 16:03:28.428376       1 serving.go:386] Generated self-signed cert in-memory
I0317 16:03:28.591744       1 controllermanager.go:185] ""Starting"" version=""v1.32.0""
I0317 16:03:28.591757       1 controllermanager.go:187] ""Golang settings"" GOGC="""" GOMAXPROCS="""" GOTRACEBACK=""""
I0317 16:03:28.592773       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0317 16:03:28.594296       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""request-header::/var/lib/minikube/certs/front-proxy-ca.crt""
I0317 16:03:28.594305       1 tlsconfig.go:243] ""Starting DynamicServingCertificateController""
I0317 16:03:28.594309       1 dynamic_cafile_content.go:161] ""Starting controller"" name=""client-ca-bundle::/var/lib/minikube/certs/ca.crt""
I0317 16:03:35.432795       1 controllermanager.go:765] ""Started controller"" controller=""serviceaccount-token-controller""
I0317 16:03:35.433534       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0317 16:03:35.435043       1 contr",0
kube-system,kube-proxy-2nh4w,Running,0,,"I0317 16:03:31.250010       1 server_linux.go:66] ""Using iptables proxy""
I0317 16:03:31.406139       1 server.go:698] ""Successfully retrieved node IP(s)"" IPs=[""192.168.49.2""]
E0317 16:03:31.406177       1 server.go:234] ""Kube-proxy configuration may be incomplete or incorrect"" err=""nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`""
I0317 16:03:31.419211       1 server.go:243] ""kube-proxy running in dual-stack mode"" primary ipFamily=""IPv4""
I0317 16:03:31.419236       1 server_linux.go:170] ""Using iptables Proxier""
I0317 16:03:31.420296       1 proxier.go:255] ""Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"" ipFamily=""IPv4""
I0317 16:03:31.421304       1 server.go:497] ""Version info"" version=""v1.32.0""
I0317 16:03:31.421317       1 se
Additional debug info: Timeout detected.",0
kube-system,kube-scheduler-minikube,Running,3,,"I0317 16:03:28.165030       1 serving.go:386] Generated self-signed cert in-memory
W0317 16:03:29.429364       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0317 16:03:29.429401       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps ""extension-apiserver-authentication"" is forbidden: User ""system:kube-scheduler"" cannot get resource ""configmaps"" in API group """" in the namespace ""kube-system""
W0317 16:03:29.429412       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0317 16:03:29.429417       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0317 16:03:29.524173       1",0
kube-system,metrics-server-57c6857795-hgscc,Running,2,,"I0317 16:34:04.907629       1 serving.go:374] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key)
I0317 16:34:05.123594       1 handler.go:275] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0317 16:34:05.228109       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I0317 16:34:05.228127       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::client-ca-file""
I0317 16:34:05.228137       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0317 16:34:05.228132       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
I0317 16:34:05.228150       1 configmap_cafile_content.go:202] ""Starting controller"" name=""client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file""
I0317 16:34:05.228157       1 shared_inform",0
kube-system,storage-provisioner,Running,1,,"I0317 16:04:14.361674       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0317 16:04:14.368524       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0317 16:04:14.368765       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0317 16:04:31.779903       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0317 16:04:31.780075       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d!
I0317 16:04:31.780642       1 event.go:282] Event(v1.ObjectReference{Kind:""Endpoints"", Namespace:""kube-system"", Name:""k8s.io-minikube-hostpath"", UID:""e1317a39-602d-4027-8118-84eeb68f5fe8"", APIVersion:""v1"", ResourceVersion:""5533"", FieldPath:""""}): type: 'Normal' reason: 'LeaderElection' minikube_8794e990-74c6-4d5f-b165-1b3dcee8f93d became leader
I0317 16:04:31.883930       1 contr
Pod failed due to high memory consumption.",0
default,bad-image-pod-synthetic-705,Pending,0,ContainersNotReady | ErrImagePull,"16:34:17 be response can't body: fetching 'application/json', HTTP Request waiting 'Cache-Control': 2025 17 start: logs: 'Content-Type': is 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', HTTP (400) HTTPHeaderDict({'Audit-Id': 'Content-Length': Mar GMT', 'Mon, Reason: headers: image in Bad '214'}) \""bad-image-pod\"" response pod private', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" Error to 'no-cache, 'Date': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-921,Pending,3,ContainersNotReady | ErrImagePull,"'Content-Type': 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', 2025 to 17 Bad 'no-cache, Request Reason: 'Content-Length': 16:34:17 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: private', response HTTPHeaderDict({'Audit-Id': pod Mar start: logs: \""invalid-container\"" '214'}) is be in 'Cache-Control': waiting (400) pulled"",""reason"":""BadRequest"",""code"":400} Error 'Mon, image 'application/json', body: HTTP response \""bad-image-pod\"" can't GMT', HTTP 'Date': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-826,Pending,4,ContainersNotReady | ErrImagePull,"Warning waiting Reason: 'no-cache, Bad headers: 2025 HTTP body: 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', pulled"",""reason"":""BadRequest"",""code"":400} Mar '214'}) 'application/json', 'Date': start: be can't to GMT', 17 HTTP logs: private', fetching \""invalid-container\"" 16:34:17 'Mon, HTTPHeaderDict({'Audit-Id': in pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" 'Content-Length': is response response image 'Content-Type': (400) Request 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-367,Pending,3,ContainersNotReady | ErrImagePull,"'Mon, 2025 'Cache-Control': is be Bad fetching 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response body: HTTP Request 'application/json', 'Content-Type': in '214'}) 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', Mar GMT', response 16:34:17 private', 'Content-Length': \""bad-image-pod\"" headers: logs: can't pod pulled"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" (400) 'no-cache, HTTPHeaderDict({'Audit-Id': start: HTTP Error Reason: 'Date': waiting to image WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-550,Pending,6,ContainersNotReady | ErrImagePull,"'Content-Length': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod headers: Error \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Content-Type': 'Mon, 16:34:17 '214'}) fetching 'Date': Request Bad private', waiting logs: Mar is in HTTP 'Cache-Control': image body: can't to GMT', 'no-cache, 2025 'cbb260ec-c0e4-4176-bdde-15fb136b4de8', start: \""bad-image-pod\"" (400) 17 Reason: 'application/json', response pulled"",""reason"":""BadRequest"",""code"":400} response be HTTP WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-856,Pending,2,ContainersNotReady | ImagePullBackOff,"'225'}) in body: Request pull image"",""reason"":""BadRequest"",""code"":400} \""invalid-container\"" 16:35:17 17 and pod Bad 'application/json', 'Cache-Control': 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': Error 2025 'Date': to headers: HTTP trying logs: \""bad-image-pod\"" is failing Reason: 'Content-Type': 'no-cache, response GMT', HTTP start: 'Mon, private', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container fetching to Mar waiting System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-697,Pending,5,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" fetching 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request body: response \""invalid-container\"" Mar waiting 16:35:17 Error to trying '225'}) 'application/json', private', in (400) 17 Bad 'Cache-Control': is HTTPHeaderDict({'Audit-Id': GMT', pull HTTP 'Mon, 2025 to 'Date': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': Reason: HTTP pod headers: and 'Content-Type': failing response logs: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container start: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-484,Pending,6,ContainersNotReady | ImagePullBackOff,"'Content-Type': 'application/json', to fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 HTTP private', headers: GMT', waiting HTTPHeaderDict({'Audit-Id': HTTP in response '225'}) Error is Reason: logs: and pull \""invalid-container\"" 'Date': start: to pod response 'Cache-Control': \""bad-image-pod\"" 16:35:17 'no-cache, failing image"",""reason"":""BadRequest"",""code"":400} trying Mar 'Mon, Bad 'Content-Length': body: 2025 (400) 'b8eb0097-2e41-474a-b84b-b09c70fc7160', Request System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-109,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTP is body: failing headers: GMT', trying to \""bad-image-pod\"" 2025 pull response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 17 logs: Bad Error 'Content-Length': 'application/json', response Request to and fetching 'Cache-Control': start: in 16:35:17 Reason: 'Date': private', 'no-cache, HTTP '225'}) image"",""reason"":""BadRequest"",""code"":400} waiting pod 'Mon, 'b8eb0097-2e41-474a-b84b-b09c70fc7160', \""invalid-container\"" (400) Mar HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-165,Pending,5,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} pull trying \""invalid-container\"" failing 17 in Error 16:35:17 to and Bad 'Mon, '225'}) response pod HTTPHeaderDict({'Audit-Id': 'Content-Length': GMT', response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'no-cache, (400) headers: to Request 'b8eb0097-2e41-474a-b84b-b09c70fc7160', 'Date': 2025 \""bad-image-pod\"" 'Content-Type': is fetching start: 'application/json', Reason: waiting Mar 'Cache-Control': HTTP body: logs: HTTP ERROR: Container startup failed due to missing dependencies.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-257,Pending,3,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" 2025 'd53f52db-183b-4e96-973f-42f3440974dd', image"",""reason"":""BadRequest"",""code"":400} Request (400) 'Content-Length': response 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: to to GMT', failing 'no-cache, 'Mon, HTTP Mar response '225'}) private', trying in pod 'Date': 16:36:17 start: waiting headers: 'application/json', HTTP Error 17 body: HTTPHeaderDict({'Audit-Id': 'Content-Type': fetching \""invalid-container\"" pull and Reason: Bad WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-520,Pending,2,ContainersNotReady | ImagePullBackOff,"trying fetching 'Date': in pull 16:36:17 \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: start: Bad to 'no-cache, and HTTP waiting Reason: 17 pod GMT', HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': response to '225'}) response HTTP 'Mon, body: is 'd53f52db-183b-4e96-973f-42f3440974dd', private', 'Cache-Control': headers: Error Mar 2025 Request \""bad-image-pod\"" 'Content-Type': failing (400) 'application/json', Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-567,Pending,3,ContainersNotReady | ImagePullBackOff,"Bad 'application/json', 'no-cache, logs: pod 17 fetching 'Mon, private', Request HTTP (400) waiting response 'd53f52db-183b-4e96-973f-42f3440974dd', 2025 HTTPHeaderDict({'Audit-Id': failing Mar 'Content-Type': start: 16:36:17 '225'}) 'Content-Length': \""invalid-container\"" Reason: HTTP is \""bad-image-pod\"" and pull to Error 'Date': response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: in image"",""reason"":""BadRequest"",""code"":400} GMT', headers: to 'Cache-Control': trying WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-920,Pending,1,ContainersNotReady | ImagePullBackOff,"body: is 17 response image"",""reason"":""BadRequest"",""code"":400} 'd53f52db-183b-4e96-973f-42f3440974dd', private', (400) fetching pull GMT', HTTP headers: 16:36:17 'Content-Length': Bad '225'}) \""bad-image-pod\"" waiting response pod failing 2025 start: HTTP 'application/json', trying 'Date': 'Cache-Control': logs: \""invalid-container\"" to 'no-cache, 'Content-Type': Request Mar Error 'Mon, and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: in to System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-394,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP trying private', start: logs: HTTP \""invalid-container\"" pod 2025 'Mon, is Reason: to image"",""reason"":""BadRequest"",""code"":400} GMT', Request 'Content-Length': Error 'Date': headers: body: Bad \""bad-image-pod\"" 'no-cache, pull 'Content-Type': fetching '225'}) and (400) 'Cache-Control': in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', waiting Mar failing response to response 16:36:17 'd53f52db-183b-4e96-973f-42f3440974dd', HTTPHeaderDict({'Audit-Id': 17 Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-809,Pending,1,ContainersNotReady | ImagePullBackOff,"Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod logs: Warning 'Date': HTTP '225'}) Bad waiting trying 'Content-Length': response 'Mon, fetching image"",""reason"":""BadRequest"",""code"":400} and failing 'Cache-Control': HTTP Reason: in to HTTPHeaderDict({'Audit-Id': 'no-cache, 17 16:37:17 response (400) pull private', 'Content-Type': Mar \""bad-image-pod\"" body: \""invalid-container\"" 'application/json', headers: '6e263e11-cb0f-40c5-8add-a77d9b82d600', is to GMT', 2025 start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-711,Pending,2,ContainersNotReady | ImagePullBackOff,"is 'application/json', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', 'Cache-Control': trying in image"",""reason"":""BadRequest"",""code"":400} Mar fetching (400) 'Date': 2025 16:37:17 HTTP and pod Request Reason: start: Bad response '6e263e11-cb0f-40c5-8add-a77d9b82d600', '225'}) to 17 HTTP failing to response 'Content-Type': \""invalid-container\"" 'no-cache, headers: \""bad-image-pod\"" 'Content-Length': logs: HTTPHeaderDict({'Audit-Id': 'Mon, Error body: pull GMT', waiting WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-320,Pending,0,ContainersNotReady | ImagePullBackOff,"GMT', \""bad-image-pod\"" private', HTTPHeaderDict({'Audit-Id': Bad 'application/json', body: start: 'Date': \""invalid-container\"" 'Mon, 17 fetching Reason: logs: to pull response pod waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: Error HTTP '6e263e11-cb0f-40c5-8add-a77d9b82d600', Mar trying failing Request 'Content-Type': 16:37:17 '225'}) 2025 'Content-Length': is to image"",""reason"":""BadRequest"",""code"":400} and 'no-cache, (400) HTTP in 'Cache-Control': response ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-273,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Type': 16:37:17 HTTPHeaderDict({'Audit-Id': HTTP Reason: Request body: response waiting 2025 fetching 'no-cache, 'Mon, failing HTTP Bad 'Content-Length': start: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Cache-Control': response (400) GMT', 17 Mar headers: logs: Error to in \""bad-image-pod\"" 'application/json', image"",""reason"":""BadRequest"",""code"":400} and to is '225'}) pod 'Date': pull ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-688,Pending,6,ContainersNotReady | ImagePullBackOff,"failing is Bad HTTPHeaderDict({'Audit-Id': pod logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:37:17 2025 HTTP body: \""bad-image-pod\"" 'Content-Length': headers: 'Mon, HTTP response (400) start: Request response Mar fetching Reason: waiting 'Cache-Control': pull GMT', 17 to 'Date': \""invalid-container\"" '225'}) image"",""reason"":""BadRequest"",""code"":400} trying in Error private', '6e263e11-cb0f-40c5-8add-a77d9b82d600', 'Content-Type': 'no-cache, and 'application/json', to WARNING: Network timeout, retrying connection...
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-834,Pending,2,ContainersNotReady | ImagePullBackOff,"response GMT', 'Content-Type': 16:38:18 17 pod start: waiting response 2025 in trying 'Date': pull HTTPHeaderDict({'Audit-Id': to Error 'no-cache, logs: 'Mon, '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', Mar body: Bad 'application/json', 'Content-Length': \""invalid-container\"" '225'}) and failing is \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container private', headers: HTTP to fetching HTTP Request image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': Reason: (400) Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-372,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP pod to Mar Bad 'Content-Type': to fetching 'Cache-Control': (400) image"",""reason"":""BadRequest"",""code"":400} headers: HTTPHeaderDict({'Audit-Id': start: '225'}) 'Mon, and trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 'no-cache, is 'application/json', logs: pull 'Date': response Reason: private', failing Error \""invalid-container\"" 16:38:18 GMT', waiting body: '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', \""bad-image-pod\"" response 17 'Content-Length': in Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-483,Pending,0,ContainersNotReady | ImagePullBackOff,"16:38:18 \""invalid-container\"" 17 headers: HTTP (400) \""bad-image-pod\"" fetching 'Content-Type': failing HTTPHeaderDict({'Audit-Id': Bad HTTP Mar Request '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': and response 'Mon, private', 'Cache-Control': pull Reason: image"",""reason"":""BadRequest"",""code"":400} waiting 'Date': to pod to 2025 'no-cache, start: body: is trying '225'}) response Warning {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', in 'application/json', logs: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-908,Pending,6,ContainersNotReady | ImagePullBackOff,"is response GMT', Mar headers: image"",""reason"":""BadRequest"",""code"":400} and private', 'Content-Length': Bad 16:38:18 fetching waiting '225'}) \""invalid-container\"" to 'Cache-Control': Error in 'Mon, (400) pull 2025 response HTTP to failing \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 17 'Date': '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Type': body: pod 'no-cache, HTTPHeaderDict({'Audit-Id': HTTP logs: start: Request 'application/json', Reason: trying ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-178,Pending,6,ContainersNotReady | ImagePullBackOff,"Reason: headers: \""invalid-container\"" logs: \""bad-image-pod\"" to GMT', in image"",""reason"":""BadRequest"",""code"":400} 17 is HTTP Bad start: HTTP Mar 16:38:18 'no-cache, private', 'application/json', failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Request fetching pull 'Date': 'Mon, (400) '225'}) 2025 'Content-Type': Error response 'Cache-Control': pod waiting to and response body: trying '9e40044c-fe37-462f-b7f1-16e7dfd5ea8d', 'Content-Length': WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-624,Pending,1,ContainersNotReady | ImagePullBackOff,"fetching Reason: pod 'no-cache, 16:39:18 start: image"",""reason"":""BadRequest"",""code"":400} HTTP 17 and GMT', response 'Mon, 'Content-Type': 'Cache-Control': private', '194d3b6d-195b-45af-a8d2-32e1cabe8747', body: 'application/json', Error Request is Mar (400) \""invalid-container\"" logs: to response '225'}) 'Date': 2025 in to pull waiting headers: \""bad-image-pod\"" failing HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying Bad HTTP 'Content-Length': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-509,Pending,1,ContainersNotReady | ImagePullBackOff,"'194d3b6d-195b-45af-a8d2-32e1cabe8747', fetching response 'Content-Type': pod \""invalid-container\"" private', response 'Cache-Control': trying Reason: is HTTP pull HTTP 'Date': \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', (400) 17 '225'}) 'application/json', 'no-cache, in failing to Mar waiting Request to 'Mon, 16:39:18 headers: Bad logs: body: HTTPHeaderDict({'Audit-Id': 'Content-Length': 2025 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error and start: Container logs unavailable due to disk space issue.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-481,Pending,1,ContainersNotReady | ImagePullBackOff,"trying 'Date': \""bad-image-pod\"" '194d3b6d-195b-45af-a8d2-32e1cabe8747', 'Content-Length': pod pull (400) 'Content-Type': 'Mon, Mar in response GMT', to to body: Reason: image"",""reason"":""BadRequest"",""code"":400} 'application/json', HTTP failing private', '225'}) start: Request 17 is fetching 16:39:18 Bad waiting Error HTTP 2025 'Cache-Control': logs: and headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response 'no-cache, \""invalid-container\"" System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-705,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTP body: trying 'Content-Type': start: Request private', HTTP GMT', waiting to is Reason: 'Mon, 'Content-Length': 'Date': Error and pull \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) '225'}) 'application/json', 'no-cache, 'Cache-Control': headers: failing fetching HTTPHeaderDict({'Audit-Id': pod to \""bad-image-pod\"" Bad response logs: 17 Mar '194d3b6d-195b-45af-a8d2-32e1cabe8747', image"",""reason"":""BadRequest"",""code"":400} response 16:39:18 in 2025 Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-123,Pending,5,ContainersNotReady | ImagePullBackOff,"logs: to 'Cache-Control': Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) waiting GMT', Warning \""bad-image-pod\"" trying HTTP '194d3b6d-195b-45af-a8d2-32e1cabe8747', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': pod 'no-cache, start: (400) is Request 17 'Content-Type': response image"",""reason"":""BadRequest"",""code"":400} 2025 pull in 'application/json', 'Date': response private', 'Mon, fetching headers: to 16:39:18 Bad HTTP Mar failing and body: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-432,Pending,5,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'application/json', is 'Content-Type': '225'}) Bad response private', failing body: trying Error logs: 2025 response GMT', to Reason: 'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Mon, and 17 HTTP headers: fetching 16:40:18 pod in waiting pull to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) HTTPHeaderDict({'Audit-Id': Request 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Mar 'Cache-Control': 'Content-Length': start: \""bad-image-pod\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-387,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar \""bad-image-pod\"" HTTP '225'}) 'Mon, pull fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container image"",""reason"":""BadRequest"",""code"":400} Bad waiting to pod and private', 2025 (400) 17 'Date': response failing logs: 16:40:18 trying start: 'application/json', response body: Request HTTPHeaderDict({'Audit-Id': headers: in to 'no-cache, GMT', is 'Content-Type': \""invalid-container\"" 'Cache-Control': HTTP Reason: Error 'Content-Length': 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-685,Pending,5,ContainersNotReady | ImagePullBackOff,"Warning 'Content-Length': start: logs: 'Cache-Control': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container failing 2025 fetching is and 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', Reason: (400) waiting HTTPHeaderDict({'Audit-Id': Mar in 'application/json', \""invalid-container\"" private', to 'Date': pod GMT', trying headers: response 'Content-Type': Request HTTP HTTP \""bad-image-pod\"" to body: pull 'no-cache, '225'}) 16:40:18 image"",""reason"":""BadRequest"",""code"":400} Bad response 'Mon, WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-593,Pending,4,ContainersNotReady | ImagePullBackOff,"'Cache-Control': is and fetching 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', HTTP Bad 17 'Mon, \""invalid-container\"" Mar trying image"",""reason"":""BadRequest"",""code"":400} start: to response Reason: HTTP 'Date': \""bad-image-pod\"" to waiting (400) failing 'Content-Length': '225'}) 2025 'no-cache, private', Request Error logs: 'Content-Type': pull 16:40:18 GMT', body: response in 'application/json', headers: HTTPHeaderDict({'Audit-Id': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-709,Pending,6,ContainersNotReady | ImagePullBackOff,"2025 failing 'Content-Length': fetching Warning 'd518dfd5-dd74-4044-96ca-f93c6686a2ea', 16:40:18 HTTP \""invalid-container\"" is headers: pod 'Cache-Control': body: '225'}) start: pull to logs: 17 'no-cache, 'Date': 'Mon, private', trying response 'application/json', to Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and GMT', in 'Content-Type': Bad \""bad-image-pod\"" (400) HTTPHeaderDict({'Audit-Id': response image"",""reason"":""BadRequest"",""code"":400} HTTP waiting Reason: Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-620,Pending,5,ContainersNotReady | ImagePullBackOff,"response HTTPHeaderDict({'Audit-Id': '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" pod is \""invalid-container\"" 'Content-Length': logs: Error response waiting in image"",""reason"":""BadRequest"",""code"":400} to 'Cache-Control': '225'}) Mar failing 17 pull Bad 16:41:18 'application/json', 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP Request 2025 (400) body: 'Content-Type': headers: HTTP to private', fetching start: trying 'Mon, and GMT', Reason: 'Date': WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-763,Pending,3,ContainersNotReady | ImagePullBackOff,"is and 'Mon, 'Content-Type': trying pod response headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Bad 17 HTTPHeaderDict({'Audit-Id': GMT', to Reason: '402e4cad-eb98-416a-8591-f7cd023ccadc', to (400) 'Date': 'application/json', start: 'Cache-Control': Request response private', failing \""bad-image-pod\"" waiting logs: HTTP Error 'no-cache, body: HTTP image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': in '225'}) pull \""invalid-container\"" fetching 2025 16:41:18 Mar WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-423,Pending,4,ContainersNotReady | ImagePullBackOff,"17 pod start: GMT', 'Date': fetching 'no-cache, response 'Mon, HTTP to to 16:41:18 response and waiting \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container (400) 'Content-Type': pull Error 'Cache-Control': is Request image"",""reason"":""BadRequest"",""code"":400} logs: 'Content-Length': headers: in Bad 'application/json', '225'}) 2025 '402e4cad-eb98-416a-8591-f7cd023ccadc', body: Mar Reason: trying private', HTTP \""invalid-container\"" Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-696,Pending,2,ContainersNotReady | ImagePullBackOff,"headers: failing 'no-cache, response body: in fetching logs: 'application/json', and '225'}) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod Bad GMT', Request pull HTTP (400) to HTTP 'Cache-Control': Reason: 'Content-Type': 'Content-Length': 'Date': 17 16:41:18 '402e4cad-eb98-416a-8591-f7cd023ccadc', \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': is 2025 Error Mar waiting private', start: image"",""reason"":""BadRequest"",""code"":400} response \""invalid-container\"" to trying 'Mon, Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-547,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP fetching 'no-cache, \""bad-image-pod\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: waiting 'Mon, GMT', 'Content-Length': 17 body: 'Date': and to \""invalid-container\"" pod '402e4cad-eb98-416a-8591-f7cd023ccadc', start: headers: Reason: to failing Request 16:41:18 private', in 2025 Bad 'Content-Type': '225'}) image"",""reason"":""BadRequest"",""code"":400} pull Mar response (400) 'application/json', is HTTP Error trying response HTTPHeaderDict({'Audit-Id': 'Cache-Control': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-599,Pending,6,ContainersNotReady | ImagePullBackOff,"16:42:18 HTTP '225'}) 'no-cache, private', body: HTTPHeaderDict({'Audit-Id': HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', 17 response logs: 'application/json', waiting failing pod 'Cache-Control': is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container and Bad Request 'Content-Length': 2025 Reason: 'Content-Type': trying pull GMT', Mar 'Date': in \""invalid-container\"" to 'Mon, Error (400) response headers: start: fetching image"",""reason"":""BadRequest"",""code"":400} to \""bad-image-pod\"" Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-915,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', waiting Error 2025 pull Reason: to image"",""reason"":""BadRequest"",""code"":400} 'no-cache, 'application/json', Request \""bad-image-pod\"" to 'Cache-Control': headers: Mar 'Mon, 'Content-Length': (400) HTTPHeaderDict({'Audit-Id': '225'}) trying failing HTTP 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', fetching in response private', response and body: 'Content-Type': start: HTTP Bad 17 16:42:18 logs: \""invalid-container\"" is 'Date': pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-104,Pending,3,ContainersNotReady | ImagePullBackOff,"response private', \""invalid-container\"" is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 17 \""bad-image-pod\"" Request response Reason: 2025 HTTPHeaderDict({'Audit-Id': 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', logs: 16:42:18 headers: to 'Mon, pod 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} fetching 'Content-Length': waiting in start: 'application/json', trying body: (400) Error 'Cache-Control': 'no-cache, GMT', to HTTP HTTP pull Mar Bad '225'}) and failing WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-858,Pending,3,ContainersNotReady | ImagePullBackOff,"'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', GMT', and to '225'}) fetching in 'Date': response Error logs: pod Request \""invalid-container\"" 'Mon, body: Mar 16:42:18 'application/json', failing pull to start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" private', HTTP trying (400) headers: 17 'Content-Type': HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} Bad 'Cache-Control': HTTP response Reason: 'no-cache, is 2025 waiting 'Content-Length': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-361,Pending,5,ContainersNotReady | ImagePullBackOff,"'application/json', '225'}) to private', 17 'Mon, \""bad-image-pod\"" (400) body: and to waiting response response 'Cache-Control': headers: GMT', Error Request is image"",""reason"":""BadRequest"",""code"":400} 'bd4fcdbe-e79f-4c66-9361-9cc28f6030b4', Bad logs: 16:42:18 HTTPHeaderDict({'Audit-Id': Reason: HTTP HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': 'Content-Length': Mar start: 'no-cache, 'Date': fetching pod pull failing trying \""invalid-container\"" in 2025 Critical failure detected: Restarting pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-898,Pending,4,ContainersNotReady | ImagePullBackOff,"Request '225'}) 16:43:18 'Cache-Control': 17 pod Mar HTTP logs: 'Content-Length': 'no-cache, waiting \""bad-image-pod\"" response in HTTPHeaderDict({'Audit-Id': fetching and 2025 \""invalid-container\"" 'application/json', GMT', HTTP private', failing headers: body: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: start: 'Date': response Bad trying to '1afd7420-8889-462e-82ac-a04cdd29b2df', is Error image"",""reason"":""BadRequest"",""code"":400} pull 'Mon, 'Content-Type': (400) Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-829,Pending,4,ContainersNotReady | ImagePullBackOff,"to (400) Request Error response \""invalid-container\"" body: logs: image"",""reason"":""BadRequest"",""code"":400} HTTP trying Reason: 16:43:18 private', '1afd7420-8889-462e-82ac-a04cdd29b2df', response GMT', '225'}) in 'Content-Length': is failing HTTP Bad 'Mon, headers: pull Mar 17 start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Date': 'no-cache, waiting 2025 fetching 'Cache-Control': 'application/json', and \""bad-image-pod\"" pod HTTPHeaderDict({'Audit-Id': to 'Content-Type': ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-505,Pending,3,ContainersNotReady | ImagePullBackOff,"'Content-Length': logs: 16:43:18 and HTTP Request GMT', headers: pod Bad \""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" 'Date': (400) in 'Mon, '1afd7420-8889-462e-82ac-a04cdd29b2df', trying response 2025 waiting Error 17 'Cache-Control': Mar private', 'Content-Type': response fetching start: 'application/json', body: pull HTTP to '225'}) failing 'no-cache, Reason: HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-640,Pending,6,ContainersNotReady | ImagePullBackOff,"response is Error Request HTTP (400) Reason: Bad HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} to waiting response 16:43:18 to in 'application/json', 17 'Mon, '225'}) headers: body: logs: 'Date': trying \""invalid-container\"" pull HTTP 'Content-Type': '1afd7420-8889-462e-82ac-a04cdd29b2df', and start: Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pod 'Content-Length': 'no-cache, GMT', fetching 2025 private', 'Cache-Control': failing \""bad-image-pod\"" WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-348,Pending,6,ContainersNotReady | ImagePullBackOff,"pull '1afd7420-8889-462e-82ac-a04cdd29b2df', 'Mon, trying \""invalid-container\"" 16:43:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 2025 fetching to waiting 'Cache-Control': 'Content-Length': 'no-cache, (400) 'Content-Type': HTTPHeaderDict({'Audit-Id': failing in start: body: HTTP image"",""reason"":""BadRequest"",""code"":400} headers: and Error GMT', '225'}) to Bad Request logs: HTTP Reason: is response private', 'Date': pod 'application/json', 17 response \""bad-image-pod\"" Mar ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-284,Pending,3,ContainersNotReady | ImagePullBackOff,"(400) and to 'Content-Type': failing fetching in 'Date': 'Cache-Control': \""invalid-container\"" Mar response image"",""reason"":""BadRequest"",""code"":400} 2025 start: \""bad-image-pod\"" private', Error HTTPHeaderDict({'Audit-Id': 'Mon, 17 pull HTTP 16:44:18 to '225'}) trying headers: body: waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Length': Request '571231c7-4677-4df0-91cb-e095605f7d9d', logs: response Bad 'application/json', Reason: GMT', is HTTP pod 'no-cache, Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-590,Pending,3,ContainersNotReady | ImagePullBackOff,"'no-cache, trying pull HTTP 'Content-Type': headers: failing response 17 HTTPHeaderDict({'Audit-Id': '225'}) 'application/json', 'Date': to 2025 'Content-Length': body: fetching 'Cache-Control': in pod image"",""reason"":""BadRequest"",""code"":400} to Error (400) response logs: private', Request GMT', start: '571231c7-4677-4df0-91cb-e095605f7d9d', Bad \""invalid-container\"" 16:44:18 'Mon, Mar \""bad-image-pod\"" and waiting is HTTP Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-711,Pending,3,ContainersNotReady | ImagePullBackOff,"'571231c7-4677-4df0-91cb-e095605f7d9d', (400) 'application/json', 17 is Bad 'no-cache, response Reason: Mar HTTP headers: waiting HTTPHeaderDict({'Audit-Id': pull 'Content-Type': and HTTP '225'}) private', response 'Mon, to 16:44:18 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request fetching to start: failing image"",""reason"":""BadRequest"",""code"":400} 'Cache-Control': trying body: logs: pod 'Date': \""bad-image-pod\"" 'Content-Length': in 2025 \""invalid-container\"" GMT', Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-796,Pending,1,ContainersNotReady | ImagePullBackOff,"pod Error image"",""reason"":""BadRequest"",""code"":400} 'Mon, Mar 'Date': response GMT', 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: logs: private', 'no-cache, to 16:44:18 body: is failing Request HTTP 'application/json', and trying in '571231c7-4677-4df0-91cb-e095605f7d9d', Bad Reason: '225'}) 'Content-Type': start: response 'Cache-Control': 2025 fetching waiting HTTPHeaderDict({'Audit-Id': HTTP 'Content-Length': \""invalid-container\"" \""bad-image-pod\"" to (400) pull Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-577,Pending,1,ContainersNotReady | ImagePullBackOff,"Request \""bad-image-pod\"" 'Cache-Control': 'Mon, GMT', HTTP in response failing image"",""reason"":""BadRequest"",""code"":400} is 16:44:18 fetching Mar pull 'Date': to HTTPHeaderDict({'Audit-Id': Error Bad waiting Reason: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response logs: HTTP \""invalid-container\"" private', to (400) body: 2025 'application/json', and 'no-cache, pod 'Content-Type': '225'}) trying headers: 'Content-Length': '571231c7-4677-4df0-91cb-e095605f7d9d', start: 17 ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-428,Pending,5,ContainersNotReady | ImagePullBackOff,"'no-cache, HTTP image"",""reason"":""BadRequest"",""code"":400} pull response headers: Request pod fetching private', start: trying \""bad-image-pod\"" to '454f6e46-6565-4908-a903-3a1220569fc4', failing body: 'Content-Type': is waiting Mar response 'Mon, GMT', Error Bad 'Content-Length': and 'Cache-Control': HTTP 'Date': 17 logs: to 'application/json', 16:45:19 HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: '225'}) in (400) 2025 \""invalid-container\"" Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-757,Pending,4,ContainersNotReady | ImagePullBackOff,"and response HTTPHeaderDict({'Audit-Id': GMT', is '225'}) \""bad-image-pod\"" Bad 'Mon, 'Date': Error response Mar HTTP body: 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to \""invalid-container\"" headers: image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': pod pull 17 logs: (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', 'Cache-Control': 'application/json', Reason: 'Content-Type': trying HTTP Request start: private', in 2025 waiting to fetching 16:45:19 Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-792,Pending,2,ContainersNotReady | ImagePullBackOff,"Mar pod GMT', (400) 'Cache-Control': image"",""reason"":""BadRequest"",""code"":400} failing 'Content-Length': to Request 16:45:19 '454f6e46-6565-4908-a903-3a1220569fc4', fetching body: HTTP 'Mon, HTTP Reason: Bad 17 logs: private', 'Content-Type': headers: is response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 start: 'no-cache, response \""invalid-container\"" to 'Date': and pull Error in 'application/json', trying \""bad-image-pod\"" waiting '225'}) System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-936,Pending,4,ContainersNotReady | ImagePullBackOff,"headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container '225'}) Bad body: to trying response HTTP 'Mon, and response is 'no-cache, fetching 'Cache-Control': 'Date': 17 logs: 16:45:19 'Content-Length': private', waiting pod \""bad-image-pod\"" start: Error Mar in '454f6e46-6565-4908-a903-3a1220569fc4', Request to 2025 \""invalid-container\"" Reason: HTTP (400) pull 'Content-Type': HTTPHeaderDict({'Audit-Id': failing 'application/json', image"",""reason"":""BadRequest"",""code"":400} GMT', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-248,Pending,4,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" 'Date': \""bad-image-pod\"" response trying image"",""reason"":""BadRequest"",""code"":400} in waiting fetching private', '225'}) to 16:45:19 pull and 'application/json', Bad is 'Content-Length': HTTP {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', to headers: 'Cache-Control': response 2025 (400) failing '454f6e46-6565-4908-a903-3a1220569fc4', HTTP Reason: 'no-cache, Error body: logs: start: 17 HTTPHeaderDict({'Audit-Id': Mar 'Content-Type': Request 'Mon, pod System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-599,Pending,4,ContainersNotReady | ImagePullBackOff,"response 'no-cache, waiting 'Date': is headers: (400) and 'application/json', to Bad pull '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': 'Mon, Request Mar body: Error HTTP 'Content-Type': to HTTPHeaderDict({'Audit-Id': logs: 2025 in 'Cache-Control': HTTP GMT', start: \""bad-image-pod\"" 17 Reason: fetching failing response pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" '225'}) 16:46:19 private', image"",""reason"":""BadRequest"",""code"":400} trying ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-316,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, 'application/json', start: 2025 'no-cache, Error image"",""reason"":""BadRequest"",""code"":400} 16:46:19 fetching 'Content-Type': 17 Request Mar response failing pod HTTPHeaderDict({'Audit-Id': trying in to Bad '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Date': '225'}) (400) private', body: GMT', and Reason: logs: to \""invalid-container\"" response \""bad-image-pod\"" HTTP pull HTTP 'Content-Length': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: 'Cache-Control': is WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-697,Pending,4,ContainersNotReady | ImagePullBackOff,"to trying '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', logs: waiting pod Request 'Cache-Control': 'application/json', 16:46:19 (400) Mar in \""invalid-container\"" '225'}) response 'Content-Length': is body: response fetching private', HTTP Reason: 'Date': 'Content-Type': HTTPHeaderDict({'Audit-Id': 17 start: to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Error 2025 failing image"",""reason"":""BadRequest"",""code"":400} pull GMT', and \""bad-image-pod\"" HTTP 'Mon, Bad headers: Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-590,Pending,2,ContainersNotReady | ImagePullBackOff,"body: private', start: waiting 'Cache-Control': 16:46:19 Bad '225'}) Error response in image"",""reason"":""BadRequest"",""code"":400} HTTPHeaderDict({'Audit-Id': 'Content-Type': 17 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to Reason: is HTTP 'no-cache, fetching 'application/json', Request HTTP response '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', 'Content-Length': pod 2025 'Mon, GMT', \""invalid-container\"" headers: trying and \""bad-image-pod\"" failing (400) 'Date': pull logs: Mar to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-785,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP 'Content-Type': 'application/json', response \""invalid-container\"" (400) pod headers: to waiting '225'}) 'no-cache, pull trying fetching to start: \""bad-image-pod\"" 'Mon, 16:46:19 in GMT', and image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request body: private', HTTPHeaderDict({'Audit-Id': 2025 is failing '5a5210e0-eac1-45a3-9ccd-809e53a4ef6e', Bad Mar 'Content-Length': response 'Date': HTTP 17 Error Reason: 'Cache-Control': logs: WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-107,Pending,5,ContainersNotReady | ImagePullBackOff,"2025 logs: 'Mon, 'Cache-Control': GMT', failing headers: 'Content-Type': response waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, Mar pod response HTTPHeaderDict({'Audit-Id': Reason: Request HTTP and HTTP pull private', image"",""reason"":""BadRequest"",""code"":400} body: 'application/json', 16:47:19 'e713ef89-f932-43ff-b40c-d904fb4ddb80', (400) Bad 'Content-Length': '225'}) \""bad-image-pod\"" Error to trying fetching in is 17 'Date': start: \""invalid-container\"" to WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-242,Pending,4,ContainersNotReady | ImagePullBackOff,"2025 image"",""reason"":""BadRequest"",""code"":400} 'Content-Type': trying headers: (400) \""bad-image-pod\"" to '225'}) 'application/json', Mar response 'no-cache, 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Date': body: pull HTTP Bad Request pod private', to and HTTPHeaderDict({'Audit-Id': 17 'Content-Length': Reason: waiting logs: 'Cache-Control': failing 'Mon, Error response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""invalid-container\"" HTTP 16:47:19 start: is in GMT', fetching Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-574,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, failing to response start: 'Content-Length': body: response GMT', 'e713ef89-f932-43ff-b40c-d904fb4ddb80', 'Content-Type': pull Error image"",""reason"":""BadRequest"",""code"":400} Bad '225'}) HTTP private', 16:47:19 'Mon, is Request \""bad-image-pod\"" logs: \""invalid-container\"" 'Cache-Control': 2025 headers: HTTPHeaderDict({'Audit-Id': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to fetching Mar 'application/json', (400) in HTTP 17 Reason: 'Date': pod waiting and trying Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-974,Pending,3,ContainersNotReady | ImagePullBackOff,"\""bad-image-pod\"" is image"",""reason"":""BadRequest"",""code"":400} 'e713ef89-f932-43ff-b40c-d904fb4ddb80', in 16:47:19 pull 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container waiting Request fetching failing Mar to pod 'Mon, 'Date': HTTPHeaderDict({'Audit-Id': start: 17 'Content-Length': private', HTTP 'Content-Type': Reason: 'no-cache, headers: Bad and response \""invalid-container\"" 'application/json', to '225'}) logs: response HTTP 2025 (400) body: GMT', Error trying Critical failure detected: Restarting pod.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-268,Pending,1,ContainersNotReady | ImagePullBackOff,"in response 'no-cache, headers: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting trying Mar response 17 (400) GMT', Bad pull body: to 'Content-Type': \""invalid-container\"" private', failing Request Error 'Mon, is logs: 2025 '225'}) to 'Cache-Control': HTTP 'e713ef89-f932-43ff-b40c-d904fb4ddb80', HTTPHeaderDict({'Audit-Id': fetching start: \""bad-image-pod\"" 'Date': 'application/json', image"",""reason"":""BadRequest"",""code"":400} Reason: 'Content-Length': and 16:47:19 pod WARNING: Network timeout, retrying connection...
Disk IO error encountered.",1
default,bad-image-pod-synthetic-930,Pending,4,ContainersNotReady | ImagePullBackOff,"waiting 'Content-Length': 'Content-Type': fetching is Error (400) 'Date': logs: 16:48:19 private', Mar start: and response 'Cache-Control': HTTP trying 'application/json', HTTPHeaderDict({'Audit-Id': 'no-cache, Request failing image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to 'Mon, Bad headers: 17 \""bad-image-pod\"" GMT', in '225'}) response Reason: pod HTTP '9792ebc8-e6f5-459d-b303-2e9106e888d1', body: to 2025 pull \""invalid-container\"" ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-651,Pending,6,ContainersNotReady | ImagePullBackOff,"in 'Date': '9792ebc8-e6f5-459d-b303-2e9106e888d1', Mar pod 'Mon, waiting Request 2025 private', pull failing 'Cache-Control': start: headers: 16:48:19 HTTP is 'Content-Type': 'no-cache, 'application/json', fetching Bad 17 body: 'Content-Length': image"",""reason"":""BadRequest"",""code"":400} Reason: trying {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container logs: Error '225'}) response HTTP to \""invalid-container\"" (400) \""bad-image-pod\"" GMT', and to HTTPHeaderDict({'Audit-Id': response ERROR: Container startup failed due to missing dependencies.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-147,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar pod to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to response HTTPHeaderDict({'Audit-Id': pull start: 16:48:19 'Content-Length': 'Content-Type': trying 'Cache-Control': \""bad-image-pod\"" and '9792ebc8-e6f5-459d-b303-2e9106e888d1', 'Date': HTTP Error 'no-cache, failing 'application/json', waiting private', (400) 2025 headers: Reason: image"",""reason"":""BadRequest"",""code"":400} Bad is in \""invalid-container\"" '225'}) 'Mon, Request GMT', HTTP logs: 17 body: response fetching ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-406,Pending,4,ContainersNotReady | ImagePullBackOff,"HTTP start: waiting in 'application/json', 16:48:19 Mar 'Mon, is 'no-cache, logs: and Error 17 to \""bad-image-pod\"" 'Date': headers: response 'Content-Length': 2025 fetching HTTP response to body: 'Content-Type': Request private', Reason: \""invalid-container\"" HTTPHeaderDict({'Audit-Id': '225'}) GMT', failing trying pull image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Cache-Control': pod Bad '9792ebc8-e6f5-459d-b303-2e9106e888d1', (400) ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-824,Pending,4,ContainersNotReady | ImagePullBackOff,"to 16:48:19 is 'no-cache, Request '9792ebc8-e6f5-459d-b303-2e9106e888d1', in start: HTTP and Bad Mar 17 pull HTTPHeaderDict({'Audit-Id': private', waiting 'application/json', GMT', 2025 'Date': Reason: response (400) response logs: \""bad-image-pod\"" HTTP 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} trying to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: failing 'Mon, 'Cache-Control': Error fetching body: 'Content-Length': pod '225'}) \""invalid-container\"" Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-379,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': Mar 2025 Error 'application/json', response start: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', GMT', Reason: to image"",""reason"":""BadRequest"",""code"":400} 'Date': '225'}) HTTP trying 'no-cache, in to fetching pod 'Content-Type': waiting {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: and Request 'Cache-Control': logs: 16:49:19 \""invalid-container\"" 'Content-Length': HTTP 'Mon, pull 17 \""bad-image-pod\"" failing body: Bad (400) is private', response Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-678,Pending,4,ContainersNotReady | ImagePullBackOff,"pull response '225'}) 'Mon, Error Reason: to (400) 'application/json', failing response image"",""reason"":""BadRequest"",""code"":400} 'Date': 'Content-Length': headers: Request trying 'no-cache, GMT', \""bad-image-pod\"" HTTP start: in body: waiting HTTPHeaderDict({'Audit-Id': private', pod HTTP Mar {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container to '430eaf9c-c34a-4351-a111-ddcc18ae90ee', is 2025 logs: and fetching Bad 'Cache-Control': 17 16:49:19 \""invalid-container\"" 'Content-Type': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-935,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTP HTTPHeaderDict({'Audit-Id': 16:49:19 '225'}) Request headers: \""invalid-container\"" is failing 'Cache-Control': body: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', fetching and 17 Bad pull logs: waiting pod HTTP 2025 start: (400) to to \""bad-image-pod\"" image"",""reason"":""BadRequest"",""code"":400} GMT', 'Date': 'no-cache, 'Mon, 'Content-Type': response response in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Mar 'Content-Length': trying private', Reason: Error ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-120,Pending,1,ContainersNotReady | ImagePullBackOff,"start: \""bad-image-pod\"" response to 'application/json', Error to fetching 'Content-Type': body: 2025 response failing Mar \""invalid-container\"" {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'no-cache, pod image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': and in headers: Bad 'Content-Length': Request private', waiting trying GMT', HTTP HTTPHeaderDict({'Audit-Id': pull 16:49:19 HTTP (400) '225'}) 'Date': is logs: Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', 'Mon, Critical failure detected: Restarting pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-716,Pending,4,ContainersNotReady | ImagePullBackOff,"'Mon, 'no-cache, start: 'Date': response 'Cache-Control': \""bad-image-pod\"" \""invalid-container\"" 2025 '225'}) waiting 16:49:19 Reason: '430eaf9c-c34a-4351-a111-ddcc18ae90ee', HTTP 'Content-Type': and to Bad in logs: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container response headers: HTTP GMT', Error 17 (400) pod Mar pull failing Request fetching to image"",""reason"":""BadRequest"",""code"":400} private', body: trying 'Content-Length': HTTPHeaderDict({'Audit-Id': is 'application/json', Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-856,Pending,3,ContainersNotReady | ImagePullBackOff,"GMT', '225'}) to logs: (400) waiting in failing \""invalid-container\"" Reason: 'Content-Type': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Warning trying start: body: Bad pod 'application/json', 'Mon, 'no-cache, image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', pull 17 \""bad-image-pod\"" fetching private', headers: HTTPHeaderDict({'Audit-Id': 'Cache-Control': is 'Date': 2025 and Mar Request response to 'Content-Length': response HTTP HTTP ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-488,Pending,5,ContainersNotReady | ImagePullBackOff,"'Mon, '225'}) 'Cache-Control': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container GMT', Reason: 17 2025 body: in Error 'no-cache, waiting 16:50:19 image"",""reason"":""BadRequest"",""code"":400} 'Content-Length': trying pull logs: failing response response start: HTTPHeaderDict({'Audit-Id': HTTP 'application/json', (400) Bad to pod and is \""bad-image-pod\"" 'Date': 'Content-Type': headers: Mar HTTP \""invalid-container\"" 'c110ab86-04c4-40ca-8e68-96d2916def69', Request fetching to private', Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-898,Pending,4,ContainersNotReady | ImagePullBackOff,"'no-cache, fetching 2025 waiting HTTP to \""bad-image-pod\"" 'Content-Type': 'Mon, logs: response and (400) Error headers: 'Date': body: failing Bad start: Reason: Mar HTTPHeaderDict({'Audit-Id': '225'}) private', image"",""reason"":""BadRequest"",""code"":400} 16:50:19 'c110ab86-04c4-40ca-8e68-96d2916def69', 'Content-Length': response is in to trying 17 HTTP \""invalid-container\"" 'Cache-Control': GMT', Request pod {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 'application/json', Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-524,Pending,3,ContainersNotReady | ImagePullBackOff,"to private', 'Content-Length': logs: in 'Content-Type': 'c110ab86-04c4-40ca-8e68-96d2916def69', pull (400) failing HTTPHeaderDict({'Audit-Id': HTTP to 'Date': fetching 'no-cache, Mar Bad waiting response GMT', '225'}) 'Mon, HTTP trying image"",""reason"":""BadRequest"",""code"":400} Error pod headers: 'application/json', Reason: 17 \""invalid-container\"" response body: and \""bad-image-pod\"" 2025 Request is {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 16:50:19 start: 'Cache-Control': Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-683,Pending,3,ContainersNotReady | ImagePullBackOff,"body: Error {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Content-Type': response 'application/json', 2025 Bad headers: \""bad-image-pod\"" pull private', failing logs: HTTP 17 HTTP pod to Reason: start: Request \""invalid-container\"" and (400) '225'}) fetching 'Cache-Control': 'c110ab86-04c4-40ca-8e68-96d2916def69', GMT', 'Mon, 'Content-Length': response waiting 'no-cache, 16:50:19 Mar image"",""reason"":""BadRequest"",""code"":400} trying in 'Date': is HTTPHeaderDict({'Audit-Id': to ERROR: Container startup failed due to missing dependencies.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-555,Pending,1,ContainersNotReady | ImagePullBackOff,"\""invalid-container\"" fetching 'Mon, image"",""reason"":""BadRequest"",""code"":400} 2025 'd2a68a9c-29d4-4938-9b47-e65f82436095', in body: '225'}) waiting Reason: response Bad \""bad-image-pod\"" 'Cache-Control': to is 'no-cache, 'Content-Length': Warning 'Date': start: (400) HTTP GMT', logs: and to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': response HTTP Request Mar private', 16:51:20 failing pull trying 17 headers: 'Content-Type': pod 'application/json', ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-118,Pending,5,ContainersNotReady | ImagePullBackOff,"GMT', Reason: \""bad-image-pod\"" 'Mon, private', pull \""invalid-container\"" HTTPHeaderDict({'Audit-Id': 'Date': 2025 'no-cache, (400) in to response 'Content-Type': waiting start: {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', Request is 16:51:20 failing and '225'}) Mar headers: fetching body: logs: trying response Bad pod HTTP to image"",""reason"":""BadRequest"",""code"":400} 17 'Cache-Control': 'Content-Length': Error 'd2a68a9c-29d4-4938-9b47-e65f82436095', HTTP WARNING: Network timeout, retrying connection...
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-841,Pending,4,ContainersNotReady | ImagePullBackOff,"image"",""reason"":""BadRequest"",""code"":400} 16:51:20 failing response HTTP (400) \""invalid-container\"" Request 'Content-Length': \""bad-image-pod\"" body: response pull Mar 'Content-Type': and Error 17 logs: is Reason: 'd2a68a9c-29d4-4938-9b47-e65f82436095', 2025 headers: '225'}) 'Date': in 'Cache-Control': private', pod 'no-cache, 'application/json', HTTPHeaderDict({'Audit-Id': to to Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container trying 'Mon, HTTP fetching GMT', start: waiting Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-629,Pending,2,ContainersNotReady | ImagePullBackOff,"'no-cache, to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Reason: (400) HTTP 'Content-Length': '225'}) \""invalid-container\"" 'd2a68a9c-29d4-4938-9b47-e65f82436095', 'application/json', and 'Date': response trying \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 16:51:20 to waiting 'Content-Type': image"",""reason"":""BadRequest"",""code"":400} HTTP 2025 start: failing response pod is pull GMT', Request Bad 'Cache-Control': 'Mon, headers: logs: 17 body: private', Error in fetching Mar ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-742,Pending,3,ContainersNotReady | ImagePullBackOff,"trying to Mar and pod 'Content-Type': 'Date': Request fetching waiting \""invalid-container\"" image"",""reason"":""BadRequest"",""code"":400} in private', to GMT', HTTP 16:51:20 Bad headers: response start: Reason: 'Content-Length': HTTP body: response failing 17 'no-cache, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'Mon, Warning 2025 'application/json', (400) 'd2a68a9c-29d4-4938-9b47-e65f82436095', is '225'}) logs: HTTPHeaderDict({'Audit-Id': 'Cache-Control': \""bad-image-pod\"" pull WARNING: Network timeout, retrying connection...",1
default,bad-image-pod-synthetic-842,Pending,1,ContainersNotReady | ImagePullBackOff,"'Content-Length': to 'Cache-Control': '225'}) 'no-cache, (400) logs: and {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Request \""invalid-container\"" 'Mon, Bad image"",""reason"":""BadRequest"",""code"":400} failing pod Mar waiting 16:52:20 HTTP trying fetching \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': 2025 pull is in GMT', private', headers: 'application/json', 'Date': Reason: 'Content-Type': 17 '2d1a1234-6455-4e92-a9c0-4fad33012904', response to Error response body: HTTP start: Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-750,Pending,2,ContainersNotReady | ImagePullBackOff,"GMT', '2d1a1234-6455-4e92-a9c0-4fad33012904', start: 'Content-Type': HTTP 'Content-Length': 'application/json', Request failing logs: pull trying '225'}) Reason: 'Mon, 'Cache-Control': fetching \""bad-image-pod\"" (400) to and in image"",""reason"":""BadRequest"",""code"":400} Bad {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container is private', 'no-cache, Mar response HTTP HTTPHeaderDict({'Audit-Id': waiting body: to 2025 \""invalid-container\"" 16:52:20 pod response headers: 17 'Date': Error Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-444,Pending,3,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': to response 'Date': in pod GMT', Reason: is '2d1a1234-6455-4e92-a9c0-4fad33012904', logs: 'Cache-Control': trying body: waiting 16:52:20 to 'Content-Type': (400) Error 'Content-Length': 'Mon, failing {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP '225'}) fetching private', and pull Bad \""bad-image-pod\"" start: response 'application/json', headers: 'no-cache, 17 2025 \""invalid-container\"" Mar HTTP image"",""reason"":""BadRequest"",""code"":400} Request ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-170,Pending,5,ContainersNotReady | ImagePullBackOff,"'Date': HTTP 'Mon, to in 'application/json', private', Request logs: 'Content-Type': and trying '2d1a1234-6455-4e92-a9c0-4fad33012904', 2025 body: headers: response 'no-cache, pull (400) HTTP \""bad-image-pod\"" 'Content-Length': 'Cache-Control': Bad GMT', 16:52:20 failing \""invalid-container\"" is '225'}) Mar 17 pod start: waiting Error response image"",""reason"":""BadRequest"",""code"":400} fetching to {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': Reason: System overload: Unable to allocate memory for pod.
Additional debug info: Timeout detected.",1
default,bad-image-pod-synthetic-285,Pending,1,ContainersNotReady | ImagePullBackOff,"HTTPHeaderDict({'Audit-Id': 'application/json', failing Error response fetching 'no-cache, Request HTTP (400) GMT', pull 2025 pod \""bad-image-pod\"" 'Date': to logs: 17 'Content-Length': in response trying Bad body: start: private', is \""invalid-container\"" 'Cache-Control': '225'}) 16:52:20 image"",""reason"":""BadRequest"",""code"":400} {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Content-Type': '2d1a1234-6455-4e92-a9c0-4fad33012904', and 'Mon, to HTTP waiting Reason: headers: Critical failure detected: Restarting pod.",1
default,bad-image-pod-synthetic-156,Pending,5,ContainersNotReady | ImagePullBackOff,"logs: 'Content-Length': failing start: image"",""reason"":""BadRequest"",""code"":400} pod Mar Bad to body: 'Content-Type': headers: HTTP is 'application/json', 16:53:20 '225'}) response to 'Date': 'Mon, 'Cache-Control': Error \""invalid-container\"" private', 'no-cache, and (400) response \""bad-image-pod\"" 2025 in {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTP waiting Request 17 trying fetching Reason: '1384d15b-3c42-4e9a-b239-184678b05a17', pull GMT', HTTPHeaderDict({'Audit-Id': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-875,Pending,3,ContainersNotReady | ImagePullBackOff,"Mar 17 response {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Error failing Request HTTP headers: '225'}) '1384d15b-3c42-4e9a-b239-184678b05a17', and 'no-cache, \""invalid-container\"" trying pull (400) to to HTTP 16:53:20 'Content-Length': 'application/json', private', 'Cache-Control': body: response 2025 GMT', in 'Date': fetching image"",""reason"":""BadRequest"",""code"":400} is start: Bad pod logs: 'Content-Type': waiting 'Mon, Reason: \""bad-image-pod\"" HTTPHeaderDict({'Audit-Id': Container logs unavailable due to disk space issue.",1
default,bad-image-pod-synthetic-226,Pending,4,ContainersNotReady | ImagePullBackOff,"Error fetching trying waiting pod start: private', 16:53:20 'Cache-Control': HTTP 'Mon, 'Content-Length': failing 2025 response 'no-cache, Bad HTTPHeaderDict({'Audit-Id': is to 17 image"",""reason"":""BadRequest"",""code"":400} Mar \""invalid-container\"" headers: GMT', Reason: Request 'Content-Type': '1384d15b-3c42-4e9a-b239-184678b05a17', pull \""bad-image-pod\"" '225'}) (400) logs: 'application/json', in HTTP 'Date': {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container body: to and response Container logs unavailable due to disk space issue.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-789,Pending,0,ContainersNotReady | ImagePullBackOff,"Mar start: HTTP headers: '225'}) pull 'Date': waiting 2025 failing HTTPHeaderDict({'Audit-Id': GMT', Request to and image"",""reason"":""BadRequest"",""code"":400} fetching \""invalid-container\"" Bad 'Mon, body: 'application/json', in HTTP 'Cache-Control': is private', 'no-cache, 'Content-Type': (400) response response logs: Reason: Error 17 to trying '1384d15b-3c42-4e9a-b239-184678b05a17', 16:53:20 {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container \""bad-image-pod\"" pod 'Content-Length': System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-509,Pending,5,ContainersNotReady | ImagePullBackOff,"pull to '1384d15b-3c42-4e9a-b239-184678b05a17', Mar 'no-cache, 16:53:20 is Warning 'Date': in trying 'Mon, GMT', HTTPHeaderDict({'Audit-Id': and pod \""bad-image-pod\"" (400) image"",""reason"":""BadRequest"",""code"":400} 17 \""invalid-container\"" Reason: headers: to fetching 2025 response failing HTTP response HTTP body: 'Content-Type': logs: Request {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container 'application/json', 'Content-Length': private', '225'}) waiting start: Bad 'Cache-Control': ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-621,Pending,4,ContainersNotReady | ImagePullBackOff,"Request 2025 response \""bad-image-pod\"" response trying Error 'Content-Type': 'Mon, {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container headers: HTTPHeaderDict({'Audit-Id': private', pod Reason: 'no-cache, failing in (400) body: \""invalid-container\"" HTTP is and Bad image"",""reason"":""BadRequest"",""code"":400} 'application/json', pull 'Content-Length': 16:54:20 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', to 17 logs: fetching GMT', 'Date': waiting to HTTP start: 'Cache-Control': '225'}) Mar System overload: Unable to allocate memory for pod.
Pod failed due to high memory consumption.",1
default,bad-image-pod-synthetic-951,Pending,4,ContainersNotReady | ImagePullBackOff,"'Content-Length': 17 'Mon, is (400) logs: pull \""bad-image-pod\"" to HTTP failing 'Date': '225'}) Request response to Warning 'no-cache, HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', headers: Reason: fetching GMT', {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Mar 'Cache-Control': 'Content-Type': HTTPHeaderDict({'Audit-Id': 2025 in image"",""reason"":""BadRequest"",""code"":400} 16:54:20 'application/json', response Bad waiting pod body: start: \""invalid-container\"" trying private', and System overload: Unable to allocate memory for pod.",1
default,bad-image-pod-synthetic-801,Pending,2,ContainersNotReady | ImagePullBackOff,"HTTP Request Error GMT', 2025 Mar start: in 'application/json', fetching to \""bad-image-pod\"" 16:54:20 failing pull headers: HTTP 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting body: image"",""reason"":""BadRequest"",""code"":400} 'no-cache, response \""invalid-container\"" HTTPHeaderDict({'Audit-Id': response 17 logs: private', trying and 'Mon, 'Cache-Control': Bad '225'}) pod 'Date': Reason: 'Content-Length': 'Content-Type': is to (400) {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container Container logs unavailable due to disk space issue.
Disk IO error encountered.",1
default,bad-image-pod-synthetic-515,Pending,2,ContainersNotReady | ImagePullBackOff,"body: is HTTPHeaderDict({'Audit-Id': image"",""reason"":""BadRequest"",""code"":400} 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', waiting private', failing Reason: in fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container pull 2025 response 'Content-Length': HTTP 'Mon, 16:54:20 '225'}) Error trying Request and 17 GMT', to pod logs: to Bad 'Content-Type': 'Cache-Control': \""bad-image-pod\"" HTTP 'no-cache, \""invalid-container\"" 'Date': (400) response headers: 'application/json', Mar start: ERROR: Container startup failed due to missing dependencies.",1
default,bad-image-pod-synthetic-902,Pending,3,ContainersNotReady | ImagePullBackOff,"'Mon, to trying Request (400) 'application/json', response to in is start: 'ee77f520-de6d-417a-8aa9-45b87d43bc0b', pod 'Date': GMT', failing 'Cache-Control': logs: Error 'Content-Type': 17 headers: 16:54:20 fetching {""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""container HTTPHeaderDict({'Audit-Id': 2025 and pull 'Content-Length': Mar \""invalid-container\"" Bad \""bad-image-pod\"" '225'}) Reason: 'no-cache, waiting image"",""reason"":""BadRequest"",""code"":400} response HTTP private', body: HTTP System overload: Unable to allocate memory for pod.",1
